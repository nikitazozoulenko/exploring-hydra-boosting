{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.base import ClassifierMixin, RegressorMixin\n",
    "from tsml.base import BaseTimeSeriesEstimator\n",
    "\n",
    "from models.random_feature_representation_boosting import HydraBoost\n",
    "\n",
    "\n",
    "class TSMLWrapperHydraBoost(RegressorMixin, BaseTimeSeriesEstimator):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super(TSMLWrapperHydraBoost, self).__init__()\n",
    "        self.hydraboost = HydraBoost(\n",
    "            n_layers=1,\n",
    "            init_n_kernels=8,\n",
    "            init_n_groups=64,\n",
    "            n_kernels=8,\n",
    "            n_groups=64,\n",
    "            max_num_channels=3,\n",
    "            hydra_batch_size=10000,\n",
    "            l2_reg=10,\n",
    "            l2_ghat=0.1,\n",
    "            boost_lr=1,\n",
    "            train_top_at = [0, 5, 10],\n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> object:\n",
    "        \"\"\"Fit the estimator to training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 3D np.ndarray of shape (n_instances, n_channels, n_timepoints)\n",
    "            The training data.\n",
    "        y : 1D np.ndarray of shape (n_instances)\n",
    "            The target labels for fitting, indices correspond to instance indices in X\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self :\n",
    "            Reference to self.\n",
    "        \"\"\"\n",
    "        X = torch.from_numpy(X).float()\n",
    "        y = torch.from_numpy(y).float()\n",
    "        y = y.unsqueeze(1)\n",
    "        self.X_mean = X.mean()\n",
    "        self.X_std = X.std()\n",
    "        self.y_mean = y.mean()\n",
    "        self.y_std = y.std()\n",
    "        X = (X - self.X_mean) / self.X_std\n",
    "        y = (y - self.y_mean) / self.y_std\n",
    "        self.hydraboost.fit(X, y)\n",
    "        return self\n",
    "\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Predicts labels for sequences in X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 3D np.ndarray of shape (n_instances, n_channels, n_timepoints)\n",
    "            The training data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y : array-like of shape (n_instances)\n",
    "            Predicted target labels.\n",
    "        \"\"\"\n",
    "        X = torch.from_numpy(X).float()\n",
    "        X = (X - self.X_mean) / self.X_std\n",
    "        pred = self.hydraboost(X)\n",
    "        pred = pred * self.y_std + self.y_mean\n",
    "        return pred.squeeze().detach().numpy()\n",
    "        \n",
    "        \n",
    "\n",
    "    def _more_tags(self) -> dict:\n",
    "        return {\n",
    "            \"X_types\": [\"3darray\"],\n",
    "            \"equal_length_only\": True,\n",
    "            \"allow_nan\": False,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test hydra\n",
    "\n",
    "from load_datasets import get_aeon_dataset\n",
    "from pathlib import Path\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "current_dir = Path(os.path.dirname(os.getcwd()))\n",
    "TSER_data_dir = current_dir.parent / \"Data\" / \"TSER\"\n",
    "\n",
    "dataset_name = \"HouseholdPowerConsumption1\"\n",
    "X_train, y_train, X_test, y_test = get_aeon_dataset(dataset_name, TSER_data_dir, \"regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training W0\n",
      "Phi0 shape torch.Size([745, 8192])\n"
     ]
    }
   ],
   "source": [
    "from tsml_eval.experiments import (\n",
    "    experiments,\n",
    "    get_regressor_by_name,\n",
    "    run_regression_experiment,\n",
    ")\n",
    "\n",
    "regressor = TSMLWrapperHydraBoost()\n",
    "regressor_name = \"HydraBoost\"\n",
    "run_regression_experiment(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    regressor,\n",
    "    regressor_name=regressor_name,\n",
    "    results_path=\"results/\",\n",
    "    dataset_name=dataset_name,\n",
    "    resample_id=0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1510.00549316 1170.70849609 1178.43505859 1622.09436035 1858.77246094\n",
      " 1495.05932617 1628.91577148 1896.97802734 1650.92932129 2544.23486328\n",
      " 1278.6529541  1892.38989258 1651.71606445 1585.17956543 1465.96191406\n",
      " 1504.0057373  1239.76599121 1250.55957031 1211.29248047  808.8336792\n",
      "  601.12329102  950.824646   1650.59765625 2180.95556641 2282.46972656\n",
      " 1868.14770508 1752.98742676 1815.85534668 2140.64648438 1978.05517578\n",
      " 2137.33740234 1913.60131836 1775.59741211 1826.87768555 1917.11694336\n",
      " 1232.08532715 2106.20776367 1533.87634277 1655.32202148 1154.3416748\n",
      " 1184.1081543  1064.35253906  988.13885498  647.23150635 1043.73535156\n",
      " 1355.83752441 2259.45776367 1776.95117188 2069.63696289 1636.27404785\n",
      " 2099.3996582  1776.62316895 1781.61425781 2733.54199219 1405.57336426\n",
      " 2496.07421875 1976.60913086 2427.68579102 1650.45593262 1448.57824707\n",
      " 1581.78271484 1203.49243164 1465.91894531 1122.64611816 1184.24475098\n",
      " 1053.58325195  582.07012939 1254.50341797 1353.69897461 1698.59179688\n",
      " 1850.66320801 1270.33825684 1456.7467041  1589.98999023 1704.1003418\n",
      " 1740.67297363 2062.86450195 1874.89770508 1909.99072266 1688.36694336\n",
      " 1828.87390137 1403.64147949 1380.93933105 2122.41943359 1129.09143066\n",
      " 1932.36157227  596.29882812 1078.92749023 1014.49755859  536.10559082\n",
      " 2052.33764648 1796.6574707  2127.25683594 1404.00927734 1902.79833984\n",
      " 1557.52416992 1806.50061035 2289.96166992 1784.27368164 2261.68945312\n",
      " 1656.46972656 2452.44458008 1716.80761719 1616.29284668 1243.21142578\n",
      " 1864.86181641 -354.06140137 1612.41552734  598.63616943 1367.93505859\n",
      "  826.64746094  529.01696777 1593.3482666  1071.22705078 1694.50817871\n",
      " 1156.78723145 1746.74951172 2110.08081055 2571.35986328 1915.42553711\n",
      " 2024.22241211 2449.48046875 1947.24267578 2150.98242188 1573.80847168\n",
      " 1398.80957031 1750.15441895 1509.59753418 1926.0847168  1248.25\n",
      " 1041.82006836 1251.96386719  824.67651367  525.31323242 1395.09838867\n",
      " 1442.7010498  1619.15148926 2349.46459961 1365.47973633 1443.57885742\n",
      " 1888.11804199 1781.78234863 2103.9621582  1650.13830566 2107.75073242\n",
      " 1982.69726562 1857.61889648 1137.60449219 1691.83789062 1429.61804199\n",
      " 1945.93835449 1330.30993652 1171.22473145  739.62463379 1563.01062012\n",
      " 1536.9744873  1072.86083984 1434.50146484  993.59796143 2812.65722656\n",
      " 2190.36767578 1502.18701172 1011.54064941 1602.90673828 1459.61108398\n",
      " 1957.83435059 1379.98095703 1773.04577637 1462.14990234 1334.94372559\n",
      " 1552.31518555 1528.77697754 1790.01000977 2178.63720703 1677.05664062\n",
      " 1779.33886719  564.66088867  828.14001465 1232.14294434 1121.95153809\n",
      " 1732.46606445 1372.56689453 2813.17333984 2077.59863281 2573.14135742\n",
      " 1091.88952637 1670.43737793 1620.36706543 1858.98168945  941.98724365\n",
      " 2164.57983398 1957.05529785 2071.25341797 1785.88818359 1620.64221191\n",
      " 1410.1673584  1679.42163086 1029.77514648 1124.88208008  714.25177002\n",
      "  757.18737793  929.75402832  988.19256592 1276.30236816 1568.73071289\n",
      " 2882.56005859 1841.84521484 1489.93115234 2521.04052734 2628.04980469\n",
      " 1782.27661133 1814.17480469  904.85144043 1736.12658691 1665.32897949\n",
      " 1481.46911621 1622.25488281 1371.29492188 1124.54980469 1363.68640137\n",
      " 1101.29089355 1340.33618164  929.05718994  706.644104   1134.47583008\n",
      " 1322.07507324 1359.05224609 1717.9453125  2408.71142578 1403.69580078\n",
      " 1779.50268555 1439.48095703 1720.27062988 2182.14257812  770.25567627\n",
      " 1948.31640625 1236.31762695 1532.32568359 1432.02954102 1845.32116699\n",
      " 1535.64160156 1441.75012207 1015.92938232 1416.76855469 1144.81921387\n",
      "  759.95629883  938.92657471 2002.31274414 1017.92913818 2301.96044922\n",
      " 1368.890625   1227.92529297 1848.19055176 1547.89990234 1470.69848633\n",
      " 2201.51757812 1786.41040039 1898.0871582  1518.0970459   795.67333984\n",
      " 1692.72155762 1666.60900879 1362.97155762 2140.69506836 1079.78564453\n",
      " 1004.07177734 1365.80456543 1301.75695801  478.89355469  717.68444824\n",
      " 1215.43481445 1296.56494141 1871.09313965 2251.60424805 1730.0012207\n",
      " 1600.80859375 1855.79858398 2071.55883789 1389.31762695 1837.64404297\n",
      " 1973.36486816 1489.2121582   455.52770996 1453.25097656 1719.5\n",
      " 1278.08007812 1090.48571777 1257.06665039 1720.88562012  726.79876709\n",
      "  844.3928833   956.28491211 2058.97216797 1650.79223633 1922.16601562\n",
      " 1987.82128906 1912.3815918  1410.02233887 2294.26977539 1134.20178223\n",
      " 2067.296875   1371.07165527 2620.98583984 1951.92858887 1299.60632324\n",
      " 1598.99523926 1524.5        1503.02124023 1388.43652344  973.97790527\n",
      " 1758.40087891  833.72906494 1111.60205078 1363.89929199 1356.78686523\n",
      " 1040.07849121 1489.97338867 1674.44873047 1489.64941406 1690.88635254\n",
      " 2364.91137695 2154.29223633 1999.62280273 2142.68896484 1506.34106445\n",
      " 1841.30041504 1671.23608398 1569.97119141 1502.04980469 1035.65063477\n",
      " 2050.90991211 1195.11303711 1598.13757324  670.2098999   910.09625244\n",
      " 1571.18933105  527.06738281 1251.2520752  1484.20031738 1921.23620605\n",
      " 2349.11694336 1784.51989746 2415.87133789 1288.12426758 1638.25805664\n",
      " 1741.92700195 2512.49804688 1637.87109375 1297.9296875  1888.84362793\n",
      " 1088.2064209  1283.6217041  1514.60559082 1385.52050781 1138.26452637\n",
      " 1352.33996582 1104.85327148 1161.1730957  1123.02880859  797.82971191\n",
      " 1617.28381348 1347.01367188 2183.07666016 2003.8659668  2570.35351562\n",
      " 2362.55957031 1977.5045166  1780.94067383 2838.83178711 1806.75268555\n",
      " 1966.1328125  1595.02990723 1915.37988281 1117.42553711 1512.74926758\n",
      " 1354.79626465 1364.97595215 1618.0090332  1138.57446289  612.02404785\n",
      "  659.69219971 1209.04174805  751.96380615 1385.26745605 1241.12988281\n",
      " 2576.44238281 1851.19702148 2364.51123047 1213.57666016 1990.34533691\n",
      " 1284.90771484 2101.74267578 1409.81323242 1759.04589844 2040.28747559\n",
      " 1543.4921875  2025.65820312 1445.27539062 1526.41809082 1264.67773438\n",
      "  847.01623535 1073.92871094  470.50695801  915.37298584 1039.1027832\n",
      " 1113.99829102 1357.85473633  202.20288086 1671.8861084  2002.1439209\n",
      " 1144.76464844 1270.97998047 1641.18481445 2238.01025391 1207.67834473\n",
      " 2140.87939453 1290.76367188 1530.59094238 1945.46972656  946.89898682\n",
      " 1385.88452148 1433.71960449 1375.43835449 1115.93847656  482.82067871\n",
      "  905.64685059 1095.39233398  821.37512207 1651.59118652 1551.3392334\n",
      " 2527.26220703 1235.98779297 1344.01416016 1499.58996582 2056.31762695\n",
      " 2043.14733887 1711.25463867 1736.23754883 1712.54504395 1247.5345459\n",
      " 1161.92822266 1465.50561523 1340.14135742 1865.69372559 1358.18847656\n",
      "  635.20422363 1165.36230469  725.52368164 1977.49487305 1521.57263184\n",
      " 2624.42236328 1834.27563477 1296.36938477 1610.09667969 1856.73620605\n",
      " 2191.76806641 1841.15637207  678.78936768 2089.47192383 2004.11083984\n",
      " 1802.49682617  876.52764893 1404.81738281 1413.92993164 1081.16638184\n",
      " 1345.6315918  1131.74780273  935.9309082  1061.26391602 1404.98498535\n",
      " 1234.46203613 1300.89245605 1590.62915039 1999.39489746 1825.50720215\n",
      " 1359.85620117 1770.67041016 2037.89868164 2367.85791016 1622.30859375\n",
      " 1621.17749023 1023.25390625 1254.20678711 1944.48974609 1116.04931641\n",
      " 1355.56237793  965.53790283  550.84545898 1332.13830566 1619.44592285\n",
      " 1189.93359375 1627.76977539 1996.55395508 2240.58911133 1679.7947998\n",
      " 1819.76525879 2065.8918457  1448.8605957  1602.50524902 1948.54016113\n",
      " 2610.45654297 1804.71520996  995.8114624  1276.04150391 1711.96777344\n",
      " 1720.8626709  1452.6003418  1390.21496582 1356.34790039  932.43554688\n",
      " 1162.69677734  514.76074219  430.41149902 1494.11486816 1398.17370605\n",
      " 2050.23950195 2688.29492188 1646.76647949 1987.54882812 1776.12756348\n",
      " 2593.49365234 1643.39477539 1703.74182129 1743.66259766 1259.12109375\n",
      " 1718.45605469 1680.96435547 1270.08129883 1112.54980469  799.08105469\n",
      "  574.84417725 1497.92028809 1445.71533203 1866.68798828 1229.53393555\n",
      " 3207.69970703 1701.02624512 2015.52709961 1355.89758301 2093.31176758\n",
      " 1967.89758301 1944.45080566 1096.64855957 1427.3034668  1076.38427734\n",
      "  623.60302734 1362.90026855 1402.8861084  1871.56921387 1878.05957031\n",
      " 1723.33483887 1594.77587891 1879.41503906 2551.89697266 1750.78759766\n",
      " 2603.28393555 2122.58959961 2083.29516602  683.78991699 2365.66015625\n",
      " 1685.35266113 1886.98828125 1343.62255859  993.72235107 1494.70336914\n",
      " 1412.83654785 1370.33703613  483.6315918   660.86895752  949.98687744\n",
      " 1562.2298584  1599.98083496 2207.97045898 1244.79467773 1642.70458984\n",
      " 1598.77478027 1650.4017334  2185.71386719 1823.26660156 1954.22802734\n",
      " 1484.03051758 1347.09619141 1553.4609375  1368.7578125  1712.30407715\n",
      " 1747.42749023 1162.08691406 2185.78344727 1465.28283691 1066.37084961\n",
      "  632.94390869  489.90087891 1511.18981934 1352.36853027 1714.91430664\n",
      " 2160.18652344 1339.45141602 1360.77929688 1533.69958496 1592.72363281\n",
      " 2249.23632812 1929.78320312 2433.05029297 1895.07495117  883.43914795\n",
      " 1491.15039062 1626.95300293 1431.37243652 1314.39672852 1511.90893555\n",
      " 1962.30505371 1003.11572266 1005.19543457  585.95275879  502.21496582\n",
      " 1198.4642334  1502.1776123  2051.01953125 1985.13378906 1675.24975586\n",
      " 1720.64782715 1478.95361328 1561.25244141 1706.56982422 3051.10742188\n",
      " 1737.72021484 1715.67785645 1371.94262695 1612.58520508 1646.64892578\n",
      " 1013.08294678 1648.07946777 1297.58374023 1085.10864258 1237.54101562\n",
      "  880.85687256  576.3939209   582.86877441 1274.56567383 1535.55200195\n",
      " 1670.41467285 1820.80419922 1522.83508301 1502.9765625  2433.97509766\n",
      " 1673.99511719 2075.93188477 2436.51245117 2194.08276367 2669.48242188\n",
      " 2637.12329102 1694.40551758 1558.26000977 1846.97570801 1773.19299316\n",
      " 1080.54174805 1332.50048828 1355.4432373  1110.32202148  375.11657715\n",
      "  578.5413208  1090.57617188 1383.66589355 1809.69213867 2613.76196289\n",
      " 1282.38012695 1359.52355957 1641.38793945 1949.91259766 1854.16113281\n",
      " 1660.72766113 2168.10766602 1893.21191406 1756.46569824 2027.42126465\n",
      " 1324.85449219 1298.37976074 1766.16235352 1356.7800293  1521.65100098\n",
      "  895.25030518  971.69830322 1027.57556152  452.2857666  1522.97546387\n",
      " 1364.453125  ]\n",
      "17413.633902655416 mse\n",
      "131.96072863793765 rmse\n",
      "0.1188387684013383 mape\n",
      "0.9346993850738128 r2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nz423\\Code\\exploring-hydra-boosting\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tsml_eval.evaluation.storage import load_regressor_results\n",
    "\n",
    "rr = load_regressor_results(\n",
    "    current_dir / \"exploring-hydra-boosting\" /\"results\" / regressor_name / \"Predictions\" / dataset_name / \"testResample0.csv\"\n",
    ")\n",
    "print(rr.predictions)\n",
    "print(rr.mean_squared_error, \"mse\")\n",
    "print(rr.root_mean_squared_error, \"rmse\")\n",
    "print(rr.mean_absolute_percentage_error, \"mape\")\n",
    "print(rr.r2_score, \"r2\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
