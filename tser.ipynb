{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List, Union, Any, Optional, Dict, Literal, Callable\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "\n",
    "import numpy as np\n",
    "import aeon\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import pandas as pd\n",
    "from aeon.datasets.tser_datasets import tser_soton; tser_soton = sorted(list(tser_soton))\n",
    "from aeon.datasets import load_regression\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.utils import print_name, print_shape\n",
    "from preprocessing.stream_transforms import normalize_mean_std_traindata, normalize_streams, augment_time, add_basepoint_zero\n",
    "from random_sig_fourier import SigTensorisedRandProj\n",
    "from signature import SigTransform, LogSigTransform\n",
    "from features.base import TimeseriesFeatureExtractor, TabularTimeseriesFeatures, RandomGuesser\n",
    "from randomized_sig import RandomizedSignature\n",
    "from rocket_wrappers import RocketWrapper, MiniRocketWrapper, MultiRocketWrapper\n",
    "\n",
    "np.set_printoptions(precision=3, threshold=5) # Print options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "#######          Dataset Code         #######\n",
    "#############################################\n",
    "\n",
    "def get_aeon_dataset(\n",
    "        dataset_name:str, \n",
    "        #extract_path = \"/rds/general/user/nz423/home/Data/TSER/\"\n",
    "        extract_path = \"/home/nikita/hdd/Data/TSER/\",\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        ):\n",
    "    \"\"\"Loads a dataset from the UCR/UEA archive using \n",
    "    the aeon library.\n",
    "\n",
    "    Args:\n",
    "        dataset_name (str): Name of the dataset\n",
    "\n",
    "    Returns:\n",
    "        Tuple: 4-tuple of the form (X_train, y_train, X_test, y_test)\n",
    "    \"\"\"\n",
    "    X_train, y_train = load_regression(dataset_name, split=\"train\", extract_path=extract_path)\n",
    "    X_test, y_test = load_regression(dataset_name, split=\"test\", extract_path=extract_path)\n",
    "    X_train = torch.from_numpy(X_train.transpose(0,2,1)).to(device)\n",
    "    X_test = torch.from_numpy(X_test.transpose(0,2,1)).to(device)\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_get_data(idx: int = 17):\n",
    "    name = tser_soton[idx]\n",
    "    X_train, y_train, X_test, y_test = get_aeon_dataset(name, device=\"cpu\")\n",
    "    print(\"Dataset:\", name)\n",
    "    print(\"idx:\", idx)\n",
    "    print(\"X_train\", X_train.shape)\n",
    "    print(\"X_test\", X_test.shape)\n",
    "\n",
    "# for i in range(20):\n",
    "#     test_get_data(i)\n",
    "#     print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "####  Linear Model (Ridge)  ######\n",
    "##################################\n",
    "\n",
    "def train_and_test_linear(\n",
    "        train_X, train_y, test_X, test_y,\n",
    "        feat_extractor: TimeseriesFeatureExtractor,\n",
    "        apply_augmentation:bool=True,\n",
    "        normalize_features:bool=True,\n",
    "        clf=RidgeCV(alphas=np.logspace(-3, 3, 20))\n",
    "    ):\n",
    "    # augment data\n",
    "    print(train_X.shape)\n",
    "    if apply_augmentation:\n",
    "        train_X, test_X = normalize_mean_std_traindata(train_X, test_X)\n",
    "        train_X = add_basepoint_zero(train_X)\n",
    "        train_X = augment_time(train_X)\n",
    "        test_X = add_basepoint_zero(test_X)\n",
    "        test_X = augment_time(test_X)\n",
    "\n",
    "    # fit transformer\n",
    "    t0 = time.time()\n",
    "    feat_extractor.fit(train_X)\n",
    "    feat_train_X = feat_extractor.transform(train_X).cpu().numpy()\n",
    "    feat_test_X = feat_extractor.transform(test_X).cpu().numpy()\n",
    "    print(\"feat_train_X\", feat_train_X.shape)\n",
    "    if normalize_features:\n",
    "        feat_train_X, feat_test_X = normalize_mean_std_traindata(feat_train_X, feat_test_X)\n",
    "\n",
    "\n",
    "    # feed into linear classifier\n",
    "    t1 = time.time()\n",
    "    clf.fit(feat_train_X, train_y)\n",
    "    t2 = time.time()\n",
    "\n",
    "    # predict\n",
    "    pred = clf.predict(feat_test_X)\n",
    "    test_rmse = root_mean_squared_error(test_y, pred)\n",
    "    train_rmse = root_mean_squared_error(train_y, clf.predict(feat_train_X))\n",
    "    alpha = clf.alpha_ if hasattr(clf, 'alpha_') else None\n",
    "    return train_rmse, test_rmse, alpha, t1-t0, t2-t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_allModels_singleDataset(X_train, y_train, X_test, y_test):\n",
    "    max_batch = 32\n",
    "    trunc_level = 4\n",
    "    n_features = 500\n",
    "\n",
    "    models = [\n",
    "        [\"Random Guesser\", RandomGuesser()],\n",
    "        [\"Tabular\", TabularTimeseriesFeatures()],\n",
    "        # [\"Sig\", SigTransform(trunc_level, max_batch)],\n",
    "        # [\"Log Sig\", LogSigTransform(trunc_level, max_batch)],\n",
    "        [\"Randomized Signature\", RandomizedSignature(\n",
    "            n_features,\n",
    "            activation = \"tanh\",\n",
    "            max_batch=10,\n",
    "            )],\n",
    "        [\"TRP\", SigTensorisedRandProj(\n",
    "            trunc_level,\n",
    "            n_features,\n",
    "            only_last=True,\n",
    "            method=\"linear\",\n",
    "            max_batch=max_batch,\n",
    "            )],\n",
    "        [\"TRP rbf\", SigTensorisedRandProj(\n",
    "            trunc_level,\n",
    "            n_features,\n",
    "            only_last=True,\n",
    "            method=\"RBF\",\n",
    "            sigma_rbf=1.0,\n",
    "            max_batch=max_batch,\n",
    "            )],\n",
    "        [\"concat TRP\", SigTensorisedRandProj(\n",
    "            trunc_level,\n",
    "            n_features // (trunc_level-1),\n",
    "            only_last=False,\n",
    "            method=\"linear\",\n",
    "            max_batch=max_batch,\n",
    "            )],\n",
    "        [\"concat TRP rbf\", SigTensorisedRandProj(\n",
    "            trunc_level,\n",
    "            n_features // (trunc_level-1),\n",
    "            only_last=False,\n",
    "            method=\"RBF\",\n",
    "            sigma_rbf=1.0,\n",
    "            max_batch=max_batch,\n",
    "            )],\n",
    "        [\"Rocket\", RocketWrapper(\n",
    "            n_features\n",
    "            )],\n",
    "        [\"MiniRocket\", MiniRocketWrapper(\n",
    "            n_features\n",
    "            )],\n",
    "        [\"MultiRocket\", MultiRocketWrapper(\n",
    "            n_features\n",
    "            )],\n",
    "        ]\n",
    "\n",
    "    # Run experiments\n",
    "    model_names = [name for (name, _) in models]\n",
    "    results_ridge = []\n",
    "    for name, model in models:\n",
    "        print(\"name\", name)\n",
    "        result = train_and_test_linear(\n",
    "            X_train, y_train, X_test, y_test, model\n",
    "            )\n",
    "        results_ridge.append(result)\n",
    "        print()\n",
    "    \n",
    "    return model_names, results_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dataset(dataset_name:str):\n",
    "    X_train, y_train, X_test, y_test = get_aeon_dataset(dataset_name)\n",
    "    X_train, X_test = normalize_streams(X_train, X_test, max_T=1000)\n",
    "    y_train, y_test = normalize_mean_std_traindata(y_train, y_test)\n",
    "    model_names, results_ridge = run_allModels_singleDataset(X_train, y_train, X_test, y_test)\n",
    "    return model_names, results_ridge\n",
    "\n",
    "model_names, results_ridge = run_dataset(tser_soton[17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_allModels_allData(datasets: List[str]):\n",
    "    #run experiments\n",
    "    experiments = {}\n",
    "    failed = {}\n",
    "    for dataset_name in tqdm(datasets):\n",
    "        t0 = time.time()\n",
    "        try:\n",
    "            print(dataset_name)\n",
    "            X_train, y_train, X_test, y_test = get_aeon_dataset(dataset_name)\n",
    "            X_train, X_test = normalize_streams(X_train, X_test, max_T=1000)\n",
    "            y_train, y_test = normalize_mean_std_traindata(y_train, y_test)\n",
    "            N_train = X_train.shape[0]\n",
    "            N_test = X_test.shape[0]\n",
    "            T = X_train.shape[1]\n",
    "            D = X_train.shape[2]\n",
    "            if N_train<=2000 and D<=20:\n",
    "                results = run_allModels_singleDataset(\n",
    "                    X_train, y_train, X_test, y_test\n",
    "                    )\n",
    "                experiments[dataset_name] = results\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            failed[dataset_name] = e\n",
    "        print(\"Elapsed time\", time.time()-t0)\n",
    "    \n",
    "    #parse results\n",
    "    # Define the attributes and methods\n",
    "    attributes = [\"RMSE_train\", \"RMSE_test\", \"alpha\", \"time_transform\", \"time_fit\"]\n",
    "    \n",
    "    # Extract model_names from d_res\n",
    "    model_names = next(iter(experiments.values()))[0]\n",
    "\n",
    "    # Create and save DataFrames for each attribute and method\n",
    "    for attribute in attributes:\n",
    "        df = pd.DataFrame(columns=model_names)\n",
    "        for dataset_name, (model_names, results_ridge) in experiments.items():\n",
    "            values = [res[attributes.index(attribute)] for res in results_ridge]\n",
    "            df.loc[dataset_name] = values\n",
    "\n",
    "        # Save the DataFrame\n",
    "        print(df)\n",
    "        df.to_pickle(f\"TESR_{attribute}_results.pkl\")\n",
    "\n",
    "    return experiments, failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_allModels_allData(tser_soton[17:19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the attributes and methods\n",
    "attributes = [\"RMSE_train\", \"RMSE_test\", \"time_transform\", \"time_fit\", \"alpha\"]\n",
    "#data_dir = \"https://github.com/nikitazozoulenko/zephyrox/raw/main/Data/TSER/\"\n",
    "data_dir = \"\"\n",
    "# Load and store the DataFrames for each attribute and method\n",
    "dfs = {}\n",
    "for attribute in attributes:\n",
    "    filename = f\"TESR_{attribute}_results.pkl\"\n",
    "    print(data_dir+filename)\n",
    "    df = pd.read_pickle(data_dir + filename)\n",
    "    dfs[attribute] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"RMSE_test\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
